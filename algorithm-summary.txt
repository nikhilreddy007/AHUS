The main idea behind the whole HUSPM approach is to reduce the number of candidate patterns that are generated. As the more canditates we have to check, The more resource intensive the algorithm becomes. This process of candidate reduction is called "Search space Pruning". In our approach, we prune the search space in multiple steps throughout the algorithm starting with "SWU Pruning"(4.1, 4.2) where we prune the initial unpromising items that are obvious. Next we apply various filters for further pruning such as "PEU Pruning"(4.5), "EUU Pruning"(4.6) and "RSU Pruning"(4.7).

After removing as many candidates as possible, We proceed further and calculate the actual utility(ASU) for all the remaining candidate patterns. And if that actual utility is high enough to meet our requirement, we consider that pattern as a High Utility Sequential Pattern(HUSP). After checking its ASU, we continue to extend that pattern by adding more items into it and apply the whole process again on the new extended pattern(using recursion). This way, by the time the algorithm completes, we will have identified all the HUSPs in our database.

The above approach in explained in a more detailed way below:


The main goal of HUSPM is to identify all the High Utility Patterns in a database. At a high level, The implemented algorithm goes through several steps to identify the HUSPs in the data-set. First and foremost, The input sequences are read from the database. These sequences contain details of all the transactions and itemsets. By analysing this data, The SWUs of all the items in the itemset can be calculated. These SWU values are used to remove all the unpromising items(low SWU items) from the dataset. This is called "SWU Pruning". Using this process, the SWUs for the new reduced dataset is recalculated and the data-set is pruned again on the basis of new SWUs. Theoritically, The more times this process is applied, the more the data-set is reduced. But generally any data-set is almost void of all unpromising items after pruned two times. As a result of removing unwanted items, the size of data-set will be slightly smaller so further process becomes more efficient.

Following the initial pruning, The actual patterns have to be generated from these sequences and be checked for their utility values to identify HUSPs. In a brute force approach, the algorithm has to go through all the possible patterns that are in the database. This way, the algorithm would need more and more resources as the pattern size increases exponentially. In a more optimized approach, It would be wise to "prune" as many patterns as possible in advance before checking for their utility values as this will be easier to compute and needs less resources. Each generated pattern is considered as a "candidate" and the the main goal of the approach is to reduce the number of candidates as much as possible. This process of candidate reduction is called "Search space Pruning". In the currently implemented approach, the pruning of search space is done in multiple steps throughout the algorithm starting with "SWU Pruning" as explained above. This is followed by various other strategies for further candidate reduction such as "PEU Pruning", "EUU Pruning" and "RSU Pruning". Each of these strategies follow different set of rules to check for any possibility of reduction of candidate patterns. Succeeding the removal of unpromising candidates products, The algorithm proceeds further to calculate the actual utility(ASU) for all the remaining candidate patterns. If the calculated actual utility is high enough to meet a specified utility threshold, That pattern is considered as a High Utility Sequential Pattern(HUSP). Subsequently, The pattern is extended by adding more items into it and this process of pruning and checking for ASU is repeated on the new extended pattern(using recursion). This way, by the time the algorithm is completed, all the HUSPs in the database are identified.

The above approach in explained in a more detailed way below: